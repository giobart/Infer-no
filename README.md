# Infer-no

Bemnchmark suite for infer Quandary

## Structure

- `/testcode` test code used to build the confusion matrix. Code directly from [OWASP/Benchmark](https://github.com/OWASP/Benchmark/tree/master/src/main/java/org/owasp/benchmark/testcode)
- `/csv/actual` the results of the benchmark are exported as a csv file directly inside this folder. Ready to be used to generate the confusion matrix.
- `/csv/expected` expected benchmark results, generated by [OWASP](https://github.com/OWASP/Benchmark)

## Setup

To install the project simply run
`python setup.py install`

To install the dependencies instead run
`pip install -r requirements.txt`

## Run the benchmark 

You can run Infer quandary against all the tests by using the following command:
`python run_tests.py `

## Print the results

If you want to generate and print the confusion matrix into your terminal use:

`python confusion_builder.py `

For each benchmark csv result file placed into `csv/actual` this script will generate a matrix.
Note that the csv file must match the structure of the official OWASP `expectedresults-1.2.csv`
