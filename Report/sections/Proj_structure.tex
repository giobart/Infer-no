\documentclass[../Report.tex]{subfiles}

\begin{document}

This project is composed of a set of Python scripts that runs the benchmark, analyses the results and creates the confusion matrix together with some statistics. 
The generation of the final results can be accomplished in 2 steps with the following scripts:

\begin{enumerate}
	\item \texttt{run\_test.py} Runs the Maven compilation of the benchmark together with the Infer quandary tool and exports the results. 
	\item \texttt{confusion\_builder.py} For each exported result from the previous step, prints statistics and the confusion matrix.
\end{enumerate}

\subsection{Custom Infer configurations}
As mentioned before, is possible to customise the analysis of the vulnerabilities with a configuration file where is possible to setup some custom sinks, endpoints, sources and sanitisers. In the case of this project, the configuration file is \texttt{benchmark/.inferconfig}.
In order to run the test with a new configuration is only necessary to edit this configuration file and run again the tool using the script mentioned at step 1.

\subsection{Compare the results}
For each time the \texttt{run\_test.py} is run, a \texttt{csv/actual/actual.csv} file is generated or overwritten. In order to compare different results from different configurations of the Quandary tool and assess the results, is possible to rename this file and run again the benchmark with the new configuration. A new \texttt{csv/actual/actual.csv} file will be generated and the old one won't be overwritten. Now, running again the script mentioned at step 2, is possible to obtain separate statistics according to all the \texttt{.csv} files placed inside the \texttt{csv/actual} folder. 


\end{document}